{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='data/', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(testloader):\n",
    "    return iter(testloader).next()\n",
    "\n",
    "def accuracy_score(y_true, y_pred, verbose=False):\n",
    "    if not verbose:\n",
    "        return np.mean(y_true == y_pred)\n",
    "    else:\n",
    "        return np.array([np.mean(y_pred_test[y_test == i] == i) for i in range(10)])\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_layers=[800, 800], droprates=[0, 0]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module(\"dropout0\",nn.Dropout(p=droprates[0]))\n",
    "        self.model.add_module(\"input\", nn.Linear(28*28, hidden_layers[0]))\n",
    "        self.model.add_module(\"tanh\", nn.Tanh())\n",
    "        for i,d in enumerate(hidden_layers[:-1]):\n",
    "            self.model.add_module(\"dropout_hidden\"+str(i+1), nn.Dropout(p=droprates[1]))\n",
    "            self.model.add_module(\"hidden\"+str(i+1), nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            self.model.add_module(\"tanh_hidden\"+str(i+1), nn.Tanh())\n",
    "        self.model.add_module(\"final\",nn.Linear(hidden_layers[-1], 10))\n",
    "        self.model.add_module(\"logsoftmax\", nn.Softmax(dim=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 28*28)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class MLPClassifier:\n",
    "    def __init__(self, hidden_layers=[800, 800], droprates=[0, 0], batch_size=100, max_epoch=10, \\\n",
    "                 lr=0.1, momentum=0.9):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.droprates = droprates\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epoch = max_epoch\n",
    "        self.model = MLP(hidden_layers=hidden_layers, droprates=droprates)\n",
    "        self.model.cuda()\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr, momentum=momentum)\n",
    "        self.loss_ = []\n",
    "        self.test_accuracy = []\n",
    "        self.test_error = []\n",
    "        \n",
    "    def fit(self, trainset, testset, verbose=True):\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=self.batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "        X_test, y_test = getData(testloader)\n",
    "        print(self)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            running_loss = 0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.data[0]\n",
    "            self.loss_.append(running_loss / len(trainloader))\n",
    "            if verbose:\n",
    "                print('Epoch {} loss: {}'.format(epoch+1, self.loss_[-1]))\n",
    "            y_test_pred = self.predict(X_test.cuda()).cpu()\n",
    "            self.test_accuracy.append(np.mean(y_test == y_test_pred))\n",
    "            self.test_error.append(int(len(testset)*(1-self.test_accuracy[-1])))\n",
    "            if verbose or epoch + 1 == self.max_epoch:\n",
    "                print('Test error: {}; test accuracy: {}'.format(self.test_error[-1], self.test_accuracy[-1]))\n",
    "        print('Finished Training.')\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        outputs = self.model(Variable(deepcopy(x)))\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        return pred\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Hidden layers: {}; dropout rates: {}'.format(self.hidden_layers, self.droprates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier([800, 800], droprates=[0.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (dropout0): Dropout(p=0.2)\n",
       "    (input): Linear(in_features=784, out_features=800, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (dropout_hidden1): Dropout(p=0.5)\n",
       "    (hidden1): Linear(in_features=800, out_features=800, bias=True)\n",
       "    (tanh_hidden1): Tanh()\n",
       "    (final): Linear(in_features=800, out_features=10, bias=True)\n",
       "    (logsoftmax): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers: [800, 800]; dropout rates: [0.2, 0.5]\n",
      "Epoch 1 loss: -0.7896569973230362\n",
      "Test error: 1483; test accuracy: 0.8516\n",
      "Epoch 2 loss: -0.8547192352016767\n",
      "Test error: 1218; test accuracy: 0.8782\n",
      "Epoch 3 loss: -0.8656575904289882\n",
      "Test error: 1257; test accuracy: 0.8743\n",
      "Epoch 4 loss: -0.8747083115577697\n",
      "Test error: 1223; test accuracy: 0.8776\n",
      "Epoch 5 loss: -0.8795649368564288\n",
      "Test error: 1152; test accuracy: 0.8847\n",
      "Epoch 6 loss: -0.8817296137412389\n",
      "Test error: 1035; test accuracy: 0.8965\n",
      "Epoch 7 loss: -0.8836222757895787\n",
      "Test error: 1118; test accuracy: 0.8882\n",
      "Epoch 8 loss: -0.8894314782818159\n",
      "Test error: 1108; test accuracy: 0.8892\n",
      "Epoch 9 loss: -0.8936932179331779\n",
      "Test error: 988; test accuracy: 0.9011\n",
      "Epoch 10 loss: -0.895119369328022\n",
      "Test error: 956; test accuracy: 0.9044\n",
      "Finished Training.\n",
      "CPU times: user 1min 3s, sys: 3.94 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MLPClassifier at 0x7f1809713a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp.fit(trainset, testset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pickle\n",
    "\n",
    "class IO:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        \n",
    "    def to_pickle(self, obj):\n",
    "        with open(self.file_name, 'wb') as output:\n",
    "            pickle.dump(obj, output, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def read_pickle(self):\n",
    "        with open(self.file_name, 'rb') as input_:\n",
    "            obj = pickle.load(input_)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \\\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='data/', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(testloader):\n",
    "    return iter(testloader).next()\n",
    "\n",
    "def accuracy_score(y_true, y_pred, verbose=False):\n",
    "    if not verbose:\n",
    "        return np.mean(y_true == y_pred)\n",
    "    else:\n",
    "        return np.array([np.mean(y_pred_test[y_test == i] == i) for i in range(10)])\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_layers=[800, 800], droprates=[0, 0]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module(\"dropout0\",nn.Dropout(p=droprates[0]))\n",
    "        self.model.add_module(\"input\", nn.Linear(28*28, hidden_layers[0]))\n",
    "        self.model.add_module(\"tanh\", nn.Tanh())\n",
    "        for i,d in enumerate(hidden_layers[:-1]):\n",
    "            self.model.add_module(\"dropout_hidden\"+str(i+1), nn.Dropout(p=droprates[1]))\n",
    "            self.model.add_module(\"hidden\"+str(i+1), nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            self.model.add_module(\"tanh_hidden\"+str(i+1), nn.Tanh())\n",
    "        self.model.add_module(\"final\",nn.Linear(hidden_layers[-1], 10))\n",
    "        #self.model.add_module(\"logsoftmax\", nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 28*28)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class MLPClassifier:\n",
    "    def __init__(self, hidden_layers=[800, 800], droprates=[0, 0], batch_size=100, max_epoch=10, \\\n",
    "                 lr=0.1, momentum=0):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.droprates = droprates\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epoch = max_epoch\n",
    "        self.model = MLP(hidden_layers=hidden_layers, droprates=droprates)\n",
    "        self.model.cuda()\n",
    "        #self.criterion = nn.NLLLoss()\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr, momentum=momentum)\n",
    "        self.loss_ = []\n",
    "        self.test_accuracy = []\n",
    "        self.test_error = []\n",
    "        \n",
    "    def fit(self, trainset, testset, verbose=True):\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=self.batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "        X_test, y_test = getData(testloader)\n",
    "        X_test = X_test.cuda()\n",
    "        print(self)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            running_loss = 0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.data[0]\n",
    "            self.loss_.append(running_loss / len(trainloader))\n",
    "            if verbose:\n",
    "                print('Epoch {} loss: {}'.format(epoch+1, self.loss_[-1]))\n",
    "            y_test_pred = self.predict(X_test).cpu()\n",
    "            self.test_accuracy.append(np.mean(y_test == y_test_pred))\n",
    "            self.test_error.append(int(len(testset)*(1-self.test_accuracy[-1])))\n",
    "            if verbose or epoch + 1 == self.max_epoch:\n",
    "                print('Test error: {}; test accuracy: {}'.format(self.test_error[-1], self.test_accuracy[-1]))\n",
    "        print('Finished Training.')\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        model = self.model.eval()\n",
    "        outputs = model(Variable(x))\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        model = self.model.train()\n",
    "        return pred\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Hidden layers: {}; dropout rates: {}'.format(self.hidden_layers, self.droprates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [800, 800]\n",
    "mlp1 = [MLPClassifier(hidden_layers, droprates=[0, 0], max_epoch=1500), \n",
    "        MLPClassifier(hidden_layers, droprates=[0, 0.5], max_epoch=1500),\n",
    "        MLPClassifier(hidden_layers, droprates=[0.2, 0.5], max_epoch=1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(mlp1[0].model)\n",
    "mlp1[0].fit(trainset, testset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(mlp1[1].model)\n",
    "mlp1[1].fit(trainset, testset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(mlp1[2].model)\n",
    "mlp1[2].fit(trainset, testset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO('results/mlp1_mnist_dropout_results_pytorch.pkl').to_pickle([(mlp.loss_, mlp.test_accuracy, mlp.test_error)\\\n",
    "                                                                for mlp in mlp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = IO('results/mlp1_mnist_dropout_results_pytorch.pkl').read_pickle()\n",
    "labels = ['no dropout', '50% dropout in hidden layers', '50% dropout in hidden layers + 20% in input layer']\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "for i, r in enumerate(results):\n",
    "    plt.plot(range(1, len(r[2])+1), r[2], '.-', label=labels[i], alpha=0.6);\n",
    "plt.ylim([80, 250]);\n",
    "plt.legend(loc=1);\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Number of errors');\n",
    "plt.title('Test error on MNIST dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
